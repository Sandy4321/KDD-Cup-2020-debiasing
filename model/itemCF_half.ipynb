{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 0\n",
      "phase: 1\n",
      "phase: 2\n",
      "phase: 3\n",
      "phase: 4\n",
      "phase: 5\n",
      "phase: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    now_phase = 6  \n",
    "    train_path = r'underexpose_train'\n",
    "    test_path = r'underexpose_test'  \n",
    "    recom_item = [] \n",
    "    \n",
    "    train_item_df = pd.read_csv(train_path+r'\\underexpose_item_feat.csv',header=None)\n",
    "    train_item_df.columns = ['item_id'] + ['txt_vec'+str(i) for i in range(128)] + ['img_vec'+str(i) for i in range(128)]\n",
    "    train_item_df['txt_vec0'] = train_item_df['txt_vec0'].apply(lambda x:float(x[1:]))\n",
    "    train_item_df['txt_vec127'] = train_item_df['txt_vec127'].apply(lambda x:float(x[:-1]))\n",
    "    train_item_df['img_vec0'] = train_item_df['img_vec0'].apply(lambda x:float(x[1:]))\n",
    "    train_item_df['img_vec127'] = train_item_df['img_vec127'].apply(lambda x:float(x[:-1]))\n",
    "\n",
    "    whole_click = pd.DataFrame()  \n",
    "    for c in range(now_phase + 1):  \n",
    "        print('phase:', c)  \n",
    "        click_train = pd.read_csv(train_path + r'\\underexpose_train_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
    "        click_test = pd.read_csv(test_path + r'\\underexpose_test_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
    "  \n",
    "        all_click = click_train.append(click_test)  \n",
    "        whole_click = whole_click.append(all_click)  \n",
    "        #all_click = all_click.drop_duplicates(subset=['user_id','item_id','time'],keep='last')\n",
    "        all_click = all_click.sort_values('time')\n",
    "\n",
    "\n",
    "    tmp = whole_click.sort_values('time')\n",
    "    tmp['next_item'] = tmp.groupby(['user_id'])['item_id'].transform(lambda x:x.shift(-1))\n",
    "    tmp['pre_item'] = tmp.groupby(['user_id'])['item_id'].transform(lambda x:x.shift(1))\n",
    "    next_item = tmp.groupby(['item_id','next_item'])['time'].agg({'count'}).reset_index().sort_values('count', ascending=False).astype(int)\n",
    "    pre_item = tmp.groupby(['item_id','pre_item'])['time'].agg({'count'}).reset_index().sort_values('count', ascending=False).astype(int)\n",
    "    next_item=next_item[next_item['next_item'].isin(train_item_df['item_id'])]\n",
    "    pre_item=pre_item[pre_item['pre_item'].isin(train_item_df['item_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 18505/18505 [20:52<00:00, 14.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 40799/40799 [00:07<00:00, 5773.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1663/1663 [00:12<00:00, 131.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 18672/18672 [20:16<00:00, 15.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 41435/41435 [00:06<00:00, 6243.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1726/1726 [00:14<00:00, 119.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 18398/18398 [20:48<00:00, 14.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 41055/41055 [00:07<00:00, 5265.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1690/1690 [00:15<00:00, 111.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 18821/18821 [25:42<00:00, 12.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42844/42844 [00:10<00:00, 4258.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1675/1675 [00:25<00:00, 66.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 18618/18618 [26:21<00:00, 11.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42867/42867 [00:09<00:00, 4566.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1708/1708 [00:22<00:00, 74.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 19459/19459 [26:32<00:00, 12.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 45661/45661 [00:11<00:00, 3910.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1798/1798 [00:27<00:00, 66.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 20396/20396 [29:40<00:00, 11.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 48693/48693 [00:10<00:00, 4647.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1821/1821 [00:23<00:00, 77.50it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "txt corr\n",
    "img corr\n",
    "'''\n",
    "import pandas as pd  \n",
    "from tqdm import tqdm  \n",
    "from collections import defaultdict  \n",
    "import math  \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "  \n",
    "def get_sim_item(df, user_col, item_col, use_iif=False):  \n",
    "    user_item_ = df.groupby(user_col)[item_col].agg(list).reset_index()\n",
    "    #user_item_ = df.groupby(user_col)[item_col].agg(set).reset_index()  \n",
    "    user_item_dict = dict(zip(user_item_[user_col], user_item_[item_col]))\n",
    "    user_time_ = df.groupby(user_col)['time'].agg(list).reset_index() # 引入时间因素\n",
    "    user_time_dict = dict(zip(user_time_[user_col], user_time_['time']))\n",
    "    \n",
    "    item_user_ = df.groupby(item_col)[user_col].agg(set).reset_index()  \n",
    "    item_user_dict = dict(zip(item_user_[item_col], item_user_[user_col])) \n",
    "    \n",
    "    sim_item = {}  \n",
    "    item_cnt = defaultdict(int)  \n",
    "    for user, items in tqdm(user_item_dict.items()):\n",
    "\n",
    "        #items2=items.copy()\n",
    "        nextitem=[]\n",
    "        for i in items:\n",
    "            temp_nextitem=next_item[next_item['item_id']==i]\n",
    "            tempcount2=temp_nextitem[temp_nextitem['count']>=10]['next_item']#[:50]\n",
    "            for j in tempcount2:\n",
    "                if j not in items:\n",
    "                    nextitem.append(j)\n",
    "        nextitem=list(set(nextitem))\n",
    "        #items=items2\n",
    "        \n",
    "        temp=train_item_df[train_item_df['item_id'].isin(items)]\n",
    "        texttemp=temp.iloc[:,:129]\n",
    "        texttemp.index=texttemp['item_id']\n",
    "        texttemp=texttemp.drop(['item_id'],axis=1)\n",
    "        texttempcorr=pd.DataFrame(texttemp.values.T, index=texttemp.columns, columns=texttemp.index).corr()\n",
    "        \n",
    "        imgtemp=temp[['item_id'] + ['img_vec'+str(i) for i in range(128)]]\n",
    "        imgtemp.index=imgtemp['item_id']\n",
    "        imgtemp=imgtemp.drop(['item_id'],axis=1)\n",
    "        imgtempcorr=pd.DataFrame(imgtemp.values.T, index=imgtemp.columns, columns=imgtemp.index).corr()\n",
    "\n",
    "        for loc1, item in enumerate(items):  \n",
    "            item_cnt[item] += 1  \n",
    "            sim_item.setdefault(item, {})  \n",
    "\n",
    "            for loc2, relate_item in enumerate(items):  \n",
    "\n",
    "                if item == relate_item:  \n",
    "                    continue\n",
    "                t1 = user_time_dict[user][loc1] # 点击时间提取\n",
    "                t2 = user_time_dict[user][loc2]\n",
    "                sim_item[item].setdefault(relate_item, 0)  \n",
    "                if not use_iif:\n",
    "                    sim_item[i][relate_item] += 1  \n",
    "                #else:\n",
    "                if (relate_item in texttempcorr.columns) & (item in texttempcorr.columns):\n",
    "\n",
    "                    if loc1-loc2>0:\n",
    "                        sim_item[item][relate_item] +=10*texttempcorr[item][relate_item]*imgtempcorr[item][relate_item] * 1 * 0.7 * (0.8**(loc1-loc2)) * (1 - (t1 - t2) * 5000) / math.log(1 + len(items))# 逆向\n",
    "\n",
    "                    else:\n",
    "                        sim_item[item][relate_item] +=10*texttempcorr[item][relate_item]*imgtempcorr[item][relate_item] * 1 * 1.0 * (0.8**(loc2-loc1)) * (1 - (t2 - t1) * 5000) / math.log(1 + len(items))# 正向\n",
    "\n",
    "                else:\n",
    "                    sim_item[item][relate_item] += 1 / math.log(1 + len(items))\n",
    " \n",
    "        for loc3,item in enumerate(nextitem):  \n",
    "            item_cnt[item] += 1  \n",
    "            sim_item.setdefault(item, {})  \n",
    "\n",
    "            for relate_item in items:  \n",
    "\n",
    "                if item == relate_item:  \n",
    "                    continue\n",
    "                sim_item[item].setdefault(relate_item, 0)  \n",
    "                if not use_iif:\n",
    "                    sim_item[item][relate_item] += 1  \n",
    "\n",
    "                if (relate_item in texttempcorr.columns) & (item in texttempcorr.columns):\n",
    "                    sim_item[item][relate_item] +=  (8/math.sqrt(loc3))*texttempcorr[item][relate_item]*imgtempcorr[item][relate_item] / math.log(1 + len(items) + len(nextitem))\n",
    "                else:\n",
    "                    sim_item[item][relate_item] += 1 / math.log(1 + len(items) + len(nextitem))\n",
    "\n",
    "    sim_item_corr = sim_item.copy()  \n",
    "    for i, related_items in tqdm(sim_item.items()):  \n",
    "        for j, cij in related_items.items():  \n",
    "            sim_item_corr[i][j] = cij/(math.log(1+item_cnt[i])*math.log(1+item_cnt[j]))  #((item_cnt[i]*item_cnt[j])**0.2)\n",
    "  \n",
    "    return sim_item_corr, user_item_dict  \n",
    "\n",
    "\n",
    "def recommend(sim_item_corr, user_item_dict, user_id, top_k, item_num):\n",
    "\n",
    "    rank = {}  \n",
    "    interacted_items = user_item_dict[user_id] \n",
    "    interacted_items = interacted_items[::-1]\n",
    "    for loc, i in enumerate(interacted_items):  \n",
    "        for j, wij in sorted(sim_item_corr[i].items(), key=lambda d: d[1], reverse=True)[0:top_k]:  \n",
    "            if j not in interacted_items:  \n",
    "                rank.setdefault(j, 0)  \n",
    "                rank[j] += wij * (0.7**loc)\n",
    "\n",
    "    return sorted(rank.items(), key=lambda d: d[1], reverse=True)[:item_num]\n",
    "  \n",
    "# fill user to 50 items  \n",
    "def get_predict(df, pred_col, top_fill):  \n",
    "    top_fill = [int(t) for t in top_fill.split(',')]  \n",
    "    scores = [-1 * i for i in range(1, len(top_fill) + 1)]  \n",
    "    ids = list(df['user_id'].unique())  \n",
    "    fill_df = pd.DataFrame(ids * len(top_fill), columns=['user_id'])  \n",
    "    fill_df.sort_values('user_id', inplace=True)  \n",
    "    fill_df['item_id'] = top_fill * len(ids)  \n",
    "    fill_df[pred_col] = scores * len(ids)  \n",
    "    df = df.append(fill_df)  \n",
    "    df.sort_values(pred_col, ascending=False, inplace=True)  \n",
    "    df = df.drop_duplicates(subset=['user_id', 'item_id'], keep='first')  \n",
    "    df['rank'] = df.groupby('user_id')[pred_col].rank(method='first', ascending=False)  \n",
    "    df = df[df['rank'] <= 50]\n",
    "\n",
    "    df = df.groupby('user_id')['item_id'].apply(lambda x: ','.join([str(i) for i in x])).str.split(',', expand=True).reset_index()\n",
    "    return df  \n",
    "  \n",
    "  \n",
    "if __name__ == \"__main__\":  \n",
    "    now_phase = 6  \n",
    "    train_path = r'underexpose_train'\n",
    "    test_path = r'underexpose_test'  \n",
    "    recom_item = [] \n",
    "    \n",
    "    train_item_df = pd.read_csv(train_path+r'\\underexpose_item_feat.csv',header=None)\n",
    "    train_item_df.columns = ['item_id'] + ['txt_vec'+str(i) for i in range(128)] + ['img_vec'+str(i) for i in range(128)]\n",
    "    train_item_df['txt_vec0'] = train_item_df['txt_vec0'].apply(lambda x:float(x[1:]))\n",
    "    train_item_df['txt_vec127'] = train_item_df['txt_vec127'].apply(lambda x:float(x[:-1]))\n",
    "    train_item_df['img_vec0'] = train_item_df['img_vec0'].apply(lambda x:float(x[1:]))\n",
    "    train_item_df['img_vec127'] = train_item_df['img_vec127'].apply(lambda x:float(x[:-1]))\n",
    "\n",
    "    whole_click = pd.DataFrame()  \n",
    "    for c in range(now_phase + 1):  \n",
    "        print('phase:', c)  \n",
    "        click_train = pd.read_csv(train_path + r'\\underexpose_train_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
    "        click_test = pd.read_csv(test_path + r'\\underexpose_test_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
    "  \n",
    "        all_click = click_train.append(click_test)  \n",
    "        whole_click = whole_click.append(all_click)  \n",
    "        #all_click = all_click.drop_duplicates(subset=['user_id','item_id','time'],keep='last')\n",
    "        all_click = all_click.sort_values('time')\n",
    "        item_sim_list, user_item = get_sim_item(all_click, 'user_id', 'item_id', use_iif=True)  \n",
    "  \n",
    "        for i in tqdm(click_test['user_id'].unique()):  \n",
    "            rank_item = recommend(item_sim_list, user_item, i, 500, 50)  \n",
    "            for j in rank_item:  \n",
    "                recom_item.append([i, j[0], j[1]])  \n",
    "\n",
    "    # find most popular items  \n",
    "    top50_click = whole_click['item_id'].value_counts().index[:50].values\n",
    "    #top50_click = whole_click[whole_click['item_id'].isin(train_item_df['item_id'])]['item_id'].value_counts().index[50:100].values\n",
    "    top50_click = ','.join([str(i) for i in top50_click])  \n",
    "  \n",
    "    recom_df = pd.DataFrame(recom_item, columns=['user_id', 'item_id', 'sim'])  \n",
    "    result = get_predict(recom_df, 'sim', top50_click)  \n",
    "    result.to_csv(r'副本.csv', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
